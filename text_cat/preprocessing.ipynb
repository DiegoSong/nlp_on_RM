{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import os\n",
    "from torchtext.data import *\n",
    "from torchtext.vocab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open(\"/Users/finup/Project/doc_cat/data/stop/stopword.txt\", 'r').readlines()\n",
    "stopwords = [i.replace('\\n', '') for i in stopwords]\n",
    "stopwords.append('LOTOzf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将文本拼成一个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data/体育 300.txt\n"
     ]
    }
   ],
   "source": [
    "def concat_files(path):\n",
    "    walk = list(os.walk(path))\n",
    "    result = []\n",
    "    cat_dict = {'文学出版':0, '校园':1, '女性':2, '体育':3}\n",
    "    for path, _, files in walk[1:]:\n",
    "        cat = cat_dict[path.split('/')[-1]]\n",
    "        for f in files:\n",
    "            try:\n",
    "                with open(os.path.join(path, f), 'r', encoding='gbk') as of:\n",
    "                    doc = of.read()\n",
    "                    doc = (str(doc)).replace(\"\\r\\n\", \"\").replace(\" \", \"\").strip()\n",
    "                    result.append([int(f.split('.')[0]), doc, cat])\n",
    "            except UnicodeDecodeError:\n",
    "                print(path, f)\n",
    "    return result\n",
    "\n",
    "train = concat_files('data/data')\n",
    "test = concat_files('data/test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train, columns=['file_idx', 'content', 'label'])\n",
    "test_df = pd.DataFrame(test, columns=['file_idx', 'content', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>289</td>\n",
       "      <td>转发微博贺超：今晚阅读李洱作品《白色的乌鸦》新星出版社20点品味书香文艺之声1066原文转发...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504</td>\n",
       "      <td>光明荐书《夜莺与玫瑰》是王尔德所著的童话作品经典选集，共收录了他的《夜莺与玫瑰》《幸福王子》...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262</td>\n",
       "      <td>《悟道》一书的编辑大人发来消息.1.卓越上《悟道》一书的在线阅读，已上线，请关注。2.当当看...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276</td>\n",
       "      <td>《人生的责任（一）》?对凡夫而言，死亡是一场灾难，因为它切断了生命和光明。但对凡夫而言，死亡...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510</td>\n",
       "      <td>《气候变化研究进展》计划于2012年出版“气候变化与第三极环境”专栏，主要内容为气候变化背景...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_idx                                            content  label\n",
       "0       289  转发微博贺超：今晚阅读李洱作品《白色的乌鸦》新星出版社20点品味书香文艺之声1066原文转发...      0\n",
       "1       504  光明荐书《夜莺与玫瑰》是王尔德所著的童话作品经典选集，共收录了他的《夜莺与玫瑰》《幸福王子》...      0\n",
       "2       262  《悟道》一书的编辑大人发来消息.1.卓越上《悟道》一书的在线阅读，已上线，请关注。2.当当看...      0\n",
       "3       276  《人生的责任（一）》?对凡夫而言，死亡是一场灾难，因为它切断了生命和光明。但对凡夫而言，死亡...      0\n",
       "4       510  《气候变化研究进展》计划于2012年出版“气候变化与第三极环境”专栏，主要内容为气候变化背景...      0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_idx</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>771</td>\n",
       "      <td>2011好书推荐《怪诞行为学》$LOTOzf$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770</td>\n",
       "      <td>陈思进撰写的《金融让谁富有》一书去年由中信出版社出版，据说该书揭开了华尔街金融机器掠夺全球财...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>772</td>\n",
       "      <td>请《结网》的读者支持一下《结网》，非常感谢！$LOTOzf$刘江:2011年度原创技术图书评...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767</td>\n",
       "      <td>悬疑小说《凡·高密码》连载──凡?高的举世名画《向日葵》里埋藏着怎样的秘密？一个疯子的传奇人...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>773</td>\n",
       "      <td>《F1速报》2011年度总集编需要您的参与，请各位读者和车迷们积极投票，并说出理由，我们会选...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>788</td>\n",
       "      <td>2011好书推荐《南方传媒研究》《品牌策划营销与管理》《科学的广告》《品牌背后的故事》$LO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>777</td>\n",
       "      <td>在读《设计中的设计|全本》★★★★★“学习下呢”http:url.cn/0eF8rs$LOT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>776</td>\n",
       "      <td>在读《青春》★★★★“其实就是博客内容，但是我还是支持。哎，想看看台湾的完整未删减版呢”ht...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>789</td>\n",
       "      <td>《苏世睿语》是一部好的人生哲理书。全书506页，50万字，共分8个部分：1.人生篇、2.生活...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>774</td>\n",
       "      <td>《倒错的死角》的确是本不错的作品，自己读起来也是希望一口气看完的（非推理小说的确没有这样的待...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>775</td>\n",
       "      <td>2011好书推荐《甄嬛传》$LOTOzf$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>787</td>\n",
       "      <td>【本周热销】1.《信睿》主编许洋信睿；2.郑渊洁《皮皮鲁送你100条命》二十一世纪出版社官方...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>793</td>\n",
       "      <td>4大奖项相继出炉，首届动漫脚本选秀大赛也到了和大家说再见的时间，以往在动漫里看见年轻人们的夏...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>778</td>\n",
       "      <td>想读《考拉小巫的英语学习日记》http:url.cn/2KAu2$LOTOzf$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>779</td>\n",
       "      <td>读过《幻城》★★★★http:url.cn/1vrWG4$LOTOzf$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>792</td>\n",
       "      <td>腾讯动漫首届动漫脚本大赛特别感谢联合主办方金龙奖（及漫友杂志金城赖春晖）、MADHOUSE北...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>786</td>\n",
       "      <td>1217互动：淘书记。淘书是一种瘾，想必很多爱看书的朋友都有同感，逛一下午旧书店，抱回一两本...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>790</td>\n",
       "      <td>首届动漫脚本选秀大赛偶像杀手经纪人、青绶传奇、画师的☆愿望3位作者已经联系到，请表与里的世界...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>784</td>\n",
       "      <td>原价68元的《史蒂夫·乔布斯传》免费下载。此版是高清扫描版，几乎接近纸质版的效果，非常不错！...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>785</td>\n",
       "      <td>【激人奋进的七个经典故事】七个激励人奋力前进的故事，看完后会对你的人生有很大的帮助，其实，这...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>791</td>\n",
       "      <td>腾讯动漫首届动漫脚本选秀大赛最后感谢每一位观赏者、传播者，大赛虽然已经结束，但是也才是迈开了...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>795</td>\n",
       "      <td>春晚前后的夏达并未有任何改变，隐居生活，全力创作自己的新作。无论是绘本《哥斯拉不说话》还是与...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>781</td>\n",
       "      <td>期望看到更多好作品加入角逐，这样我们的漫画才丰富多彩。恭喜每个漫画家~还有朱斌,新单行本又要...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>780</td>\n",
       "      <td>读过《墨迹》★★★http:url.cn/2FYTI$LOTOzf$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>794</td>\n",
       "      <td>首届动漫脚本选秀大赛暨第8届金龙奖最佳动漫脚本奖9月29日晚隆重揭晓，恭喜Saya的史上最强...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>782</td>\n",
       "      <td>这其实也是人气的一个见证哈~多谢大家支持你们喜欢的漫画~还有更多是支持正版~我们的漫画才会愈...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>796</td>\n",
       "      <td>【当当看历史】经过近一年的联络沟通，《看历史》终于在当当上架。现在当当、卓越、京东、快书包等...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>769</td>\n",
       "      <td>2011好书推荐《富可敌国》$LOTOzf$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>768</td>\n",
       "      <td>拉手网在团购《最家长》哦！37元一年，还另外多送一本，哇，超值啊！快去看看吧http:t.c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>797</td>\n",
       "      <td>2011好书推荐人生禅！$LOTOzf$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1403</td>\n",
       "      <td>【周末版预告·蒂加纳系列·申花引援系列·反赌扫黑追踪·足协会议】蒂加纳周六抵沪签约专访朱骏：...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1365</td>\n",
       "      <td>Tyloo输了，带没有让我失望好几年没看到这么精彩的比赛了谢谢~$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1371</td>\n",
       "      <td>旅游卫视本周五直播2011中国-亚太对抗赛，中国队梁文冲领衔12名顶尖球员迎战亚太队！实力选...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1417</td>\n",
       "      <td>NBA总决赛第四场,诺天王简直是\"神\",每到第四节末尾,他都能临危不惧,投进关键球,决定胜负...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1349</td>\n",
       "      <td>电台里播一场女排比赛，双方实力相当，势均力敌，比分一直焦灼着，只听解说员说道必须坚持八字方针...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1413</td>\n",
       "      <td>体坛风云人物安踏2011CCT体坛风云人物年度评选提名奖揭晓仪式到此结束，感谢大家的关注与支...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1375</td>\n",
       "      <td>雪儿？。。。。哈哈冷雪兄这个名字我喜欢啊。周四带着必胜的信念去德国||冷雪:汗，以前叫我雪妹...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1361</td>\n",
       "      <td>【林书豪“搭载”火箭　休斯敦“青睐”华人】当2002年“小巨人”姚明作为NBA历史上第一位外...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1407</td>\n",
       "      <td>12月12日消息，上海申花俱乐部(ShenhuaFC)和英超切尔西俱乐部(ChelseaFC...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1360</td>\n",
       "      <td>曼联出局，明年上半年可以少熬几个夜了。$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1406</td>\n",
       "      <td>据联盟消息透露，魔术队已经终结关于霍华德的所有交易谈判，后者新赛季将继续留在奥兰多。$LOT...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1412</td>\n",
       "      <td>体坛风云人物安踏2011CCT体坛风云人物年度评选颁奖盛典将于2012年1月15日在国家体育...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1374</td>\n",
       "      <td>恭喜女排，完胜德国没给小日本算计的机会！期待姑娘们伦敦重现雅典精彩$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1348</td>\n",
       "      <td>飞雁挥杆显爱心，2012慈善高尔夫球比赛10周年于3月23日举行。$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1438</td>\n",
       "      <td>北京时间2011年12月15日晚，福利彩票双色球第2011147期开奖，当期开出的奖号为：红...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1404</td>\n",
       "      <td>周六晚国安对长春17台下，100元球票原价转让一张。$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1362</td>\n",
       "      <td>【签林书豪火箭意图明显　双塔梦想有望实现】于是球迷肯定会有这样一个问题，为何火箭不干脆去追逐...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1376</td>\n",
       "      <td>各位亲，在浙江舟山举办的第八届残疾人运动会火炬传递首次启用导盲犬为盲人火炬手导盲哦，pp由于...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1410</td>\n",
       "      <td>NBA支持加内特，加内特的腾讯微博ID既然2字母！$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1389</td>\n",
       "      <td>梅西！$LOTOzf$腾讯体育:【哈维传射巴萨4-0捧杯梅西两球创纪录】北京时间12月18日...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1388</td>\n",
       "      <td>欧洲最佳球员又是梅西！$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1377</td>\n",
       "      <td>（南非，开普敦，12月9日）经过大修后的中国船队“三亚号”今天亮相沃尔沃环球帆船赛开普敦混合...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1411</td>\n",
       "      <td>上海男篮主场迎战新疆，帕纳吉奥PK邓华德。赛后第一时间开通热线：62561000。$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1405</td>\n",
       "      <td>据ESPN报道，洛杉矶快船队已经答应了联盟所属的新奥尔良黄蜂队关于克里斯-保罗的交易协议。快...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1363</td>\n",
       "      <td>长春362向长春亚泰发来贺电，2:1杀广州恒大，绝对牛逼啊！！http:url.cn/11q...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1439</td>\n",
       "      <td>在被称为百年一遇的2011年11月11日“神棍节”，杨先生买了一张彩票，彩票上的时间是201...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1338</td>\n",
       "      <td>意大利的新人EdoardoAlescio上周末成为WPT冠军俱乐部的一员。他在WPT威尼斯站...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1339</td>\n",
       "      <td>李娜真棒坚持到了最后国歌在法网比赛中第一次响起好激动哈$LOTOzf$</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1449</td>\n",
       "      <td>阿森纳5比3吃掉了切尔西，曼联8比2猎食阿森纳、曼城6比1煮了曼联，蓝军完成最后串联，2-1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1448</td>\n",
       "      <td>14日钢市早报：上周，国内钢材市场整体上震荡调整。欧债问题依然是投资者对未来经济走向进行判断...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_idx                                            content  label\n",
       "0         771                            2011好书推荐《怪诞行为学》$LOTOzf$      0\n",
       "1         770  陈思进撰写的《金融让谁富有》一书去年由中信出版社出版，据说该书揭开了华尔街金融机器掠夺全球财...      0\n",
       "2         772  请《结网》的读者支持一下《结网》，非常感谢！$LOTOzf$刘江:2011年度原创技术图书评...      0\n",
       "3         767  悬疑小说《凡·高密码》连载──凡?高的举世名画《向日葵》里埋藏着怎样的秘密？一个疯子的传奇人...      0\n",
       "4         773  《F1速报》2011年度总集编需要您的参与，请各位读者和车迷们积极投票，并说出理由，我们会选...      0\n",
       "5         788  2011好书推荐《南方传媒研究》《品牌策划营销与管理》《科学的广告》《品牌背后的故事》$LO...      0\n",
       "6         777  在读《设计中的设计|全本》★★★★★“学习下呢”http:url.cn/0eF8rs$LOT...      0\n",
       "7         776  在读《青春》★★★★“其实就是博客内容，但是我还是支持。哎，想看看台湾的完整未删减版呢”ht...      0\n",
       "8         789  《苏世睿语》是一部好的人生哲理书。全书506页，50万字，共分8个部分：1.人生篇、2.生活...      0\n",
       "9         774  《倒错的死角》的确是本不错的作品，自己读起来也是希望一口气看完的（非推理小说的确没有这样的待...      0\n",
       "10        775                              2011好书推荐《甄嬛传》$LOTOzf$      0\n",
       "11        787  【本周热销】1.《信睿》主编许洋信睿；2.郑渊洁《皮皮鲁送你100条命》二十一世纪出版社官方...      0\n",
       "12        793  4大奖项相继出炉，首届动漫脚本选秀大赛也到了和大家说再见的时间，以往在动漫里看见年轻人们的夏...      0\n",
       "13        778           想读《考拉小巫的英语学习日记》http:url.cn/2KAu2$LOTOzf$      0\n",
       "14        779               读过《幻城》★★★★http:url.cn/1vrWG4$LOTOzf$      0\n",
       "15        792  腾讯动漫首届动漫脚本大赛特别感谢联合主办方金龙奖（及漫友杂志金城赖春晖）、MADHOUSE北...      0\n",
       "16        786  1217互动：淘书记。淘书是一种瘾，想必很多爱看书的朋友都有同感，逛一下午旧书店，抱回一两本...      0\n",
       "17        790  首届动漫脚本选秀大赛偶像杀手经纪人、青绶传奇、画师的☆愿望3位作者已经联系到，请表与里的世界...      0\n",
       "18        784  原价68元的《史蒂夫·乔布斯传》免费下载。此版是高清扫描版，几乎接近纸质版的效果，非常不错！...      0\n",
       "19        785  【激人奋进的七个经典故事】七个激励人奋力前进的故事，看完后会对你的人生有很大的帮助，其实，这...      0\n",
       "20        791  腾讯动漫首届动漫脚本选秀大赛最后感谢每一位观赏者、传播者，大赛虽然已经结束，但是也才是迈开了...      0\n",
       "21        795  春晚前后的夏达并未有任何改变，隐居生活，全力创作自己的新作。无论是绘本《哥斯拉不说话》还是与...      0\n",
       "22        781  期望看到更多好作品加入角逐，这样我们的漫画才丰富多彩。恭喜每个漫画家~还有朱斌,新单行本又要...      0\n",
       "23        780                 读过《墨迹》★★★http:url.cn/2FYTI$LOTOzf$      0\n",
       "24        794  首届动漫脚本选秀大赛暨第8届金龙奖最佳动漫脚本奖9月29日晚隆重揭晓，恭喜Saya的史上最强...      0\n",
       "25        782  这其实也是人气的一个见证哈~多谢大家支持你们喜欢的漫画~还有更多是支持正版~我们的漫画才会愈...      0\n",
       "26        796  【当当看历史】经过近一年的联络沟通，《看历史》终于在当当上架。现在当当、卓越、京东、快书包等...      0\n",
       "27        769                             2011好书推荐《富可敌国》$LOTOzf$      0\n",
       "28        768  拉手网在团购《最家长》哦！37元一年，还另外多送一本，哇，超值啊！快去看看吧http:t.c...      0\n",
       "29        797                               2011好书推荐人生禅！$LOTOzf$      0\n",
       "..        ...                                                ...    ...\n",
       "170      1403  【周末版预告·蒂加纳系列·申花引援系列·反赌扫黑追踪·足协会议】蒂加纳周六抵沪签约专访朱骏：...      3\n",
       "171      1365           Tyloo输了，带没有让我失望好几年没看到这么精彩的比赛了谢谢~$LOTOzf$      3\n",
       "172      1371  旅游卫视本周五直播2011中国-亚太对抗赛，中国队梁文冲领衔12名顶尖球员迎战亚太队！实力选...      3\n",
       "173      1417  NBA总决赛第四场,诺天王简直是\"神\",每到第四节末尾,他都能临危不惧,投进关键球,决定胜负...      3\n",
       "174      1349  电台里播一场女排比赛，双方实力相当，势均力敌，比分一直焦灼着，只听解说员说道必须坚持八字方针...      3\n",
       "175      1413  体坛风云人物安踏2011CCT体坛风云人物年度评选提名奖揭晓仪式到此结束，感谢大家的关注与支...      3\n",
       "176      1375  雪儿？。。。。哈哈冷雪兄这个名字我喜欢啊。周四带着必胜的信念去德国||冷雪:汗，以前叫我雪妹...      3\n",
       "177      1361  【林书豪“搭载”火箭　休斯敦“青睐”华人】当2002年“小巨人”姚明作为NBA历史上第一位外...      3\n",
       "178      1407  12月12日消息，上海申花俱乐部(ShenhuaFC)和英超切尔西俱乐部(ChelseaFC...      3\n",
       "179      1360                        曼联出局，明年上半年可以少熬几个夜了。$LOTOzf$      3\n",
       "180      1406  据联盟消息透露，魔术队已经终结关于霍华德的所有交易谈判，后者新赛季将继续留在奥兰多。$LOT...      3\n",
       "181      1412  体坛风云人物安踏2011CCT体坛风云人物年度评选颁奖盛典将于2012年1月15日在国家体育...      3\n",
       "182      1374          恭喜女排，完胜德国没给小日本算计的机会！期待姑娘们伦敦重现雅典精彩$LOTOzf$      3\n",
       "183      1348          飞雁挥杆显爱心，2012慈善高尔夫球比赛10周年于3月23日举行。$LOTOzf$      3\n",
       "184      1438  北京时间2011年12月15日晚，福利彩票双色球第2011147期开奖，当期开出的奖号为：红...      3\n",
       "185      1404                 周六晚国安对长春17台下，100元球票原价转让一张。$LOTOzf$      3\n",
       "186      1362  【签林书豪火箭意图明显　双塔梦想有望实现】于是球迷肯定会有这样一个问题，为何火箭不干脆去追逐...      3\n",
       "187      1376  各位亲，在浙江舟山举办的第八届残疾人运动会火炬传递首次启用导盲犬为盲人火炬手导盲哦，pp由于...      3\n",
       "188      1410                  NBA支持加内特，加内特的腾讯微博ID既然2字母！$LOTOzf$      3\n",
       "189      1389  梅西！$LOTOzf$腾讯体育:【哈维传射巴萨4-0捧杯梅西两球创纪录】北京时间12月18日...      3\n",
       "190      1388                                欧洲最佳球员又是梅西！$LOTOzf$      3\n",
       "191      1377  （南非，开普敦，12月9日）经过大修后的中国船队“三亚号”今天亮相沃尔沃环球帆船赛开普敦混合...      3\n",
       "192      1411  上海男篮主场迎战新疆，帕纳吉奥PK邓华德。赛后第一时间开通热线：62561000。$LOTOzf$      3\n",
       "193      1405  据ESPN报道，洛杉矶快船队已经答应了联盟所属的新奥尔良黄蜂队关于克里斯-保罗的交易协议。快...      3\n",
       "194      1363  长春362向长春亚泰发来贺电，2:1杀广州恒大，绝对牛逼啊！！http:url.cn/11q...      3\n",
       "195      1439  在被称为百年一遇的2011年11月11日“神棍节”，杨先生买了一张彩票，彩票上的时间是201...      3\n",
       "196      1338  意大利的新人EdoardoAlescio上周末成为WPT冠军俱乐部的一员。他在WPT威尼斯站...      3\n",
       "197      1339                李娜真棒坚持到了最后国歌在法网比赛中第一次响起好激动哈$LOTOzf$      3\n",
       "198      1449  阿森纳5比3吃掉了切尔西，曼联8比2猎食阿森纳、曼城6比1煮了曼联，蓝军完成最后串联，2-1...      3\n",
       "199      1448  14日钢市早报：上周，国内钢材市场整体上震荡调整。欧债问题依然是投资者对未来经济走向进行判断...      3\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重要的参数：\n",
    "1. `sequential`：是否是可序列化数据（类似于字符串数据），默认值是 `True`；\n",
    "2. `user_vocab`：是否使用 `Vocab` 对象，如果取 `False`，则该字段必须是数值类型；默认值是`True`；\n",
    "3. `tokenize`：是一个 `function` 类型的对象（如 `string.cut` 、`jieba.cut` 等），用于对字符串进行分词；\n",
    "4. `batch_first`：如果该属性的值取 `True`，则该字段返回的 `Tensor` 对象的第一维度是 `batch` 的大小；默认值是`False`；\n",
    "5. `fix_length`：该字段是否是定长，如果取 `None` 则按同 `batch` 该字段的最大长度进行pad；\n",
    "6. `stop_words`：停用词，在`tokenize`步会忽视;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重要函数：\n",
    "\n",
    "`build_vocab`：为该`Field`创建`Vocab`；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT = Field(sequential=True, tokenize=jieba.cut, batch_first=True, fix_length=50, stop_words=stopwords)\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重要参数：\n",
    "1. `examples`：`Example`对象列表;\n",
    "2. `fields`：格式是`List(tuple(str, Field))`，其中 `str` 是 `Field` 对象的描述；\n",
    "\n",
    "重要函数：\n",
    "1. `split()`：此方法用于划分数据集，将数据集划分为train、test、valid数据集；\n",
    "2. `split_ratio`：此参数为 `float` 或 `list` 类型，当参数为`float`类型时（参数取值要在[0, 1]），表示数据集中多少比例的数据划分到`train`（训练）数据集里，剩余的划分到`valid`（验证）数据集里；如果该参数是`list`类型（如[0.7, 0.2, 0.1]），表示`train`，`test`、`valid`数据集的比例；该参数默认值是 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dataset构造并返回Dataset所需的examples和fields\n",
    "def get_dataset(csv_data, text_field, label_field, test=False):\n",
    "    # id数据对训练在训练过程中没用，使用None指定其对应的field\n",
    "    fields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"content\", text_field), (\"label\", label_field)]       \n",
    "    examples = []\n",
    "\n",
    "    if test:\n",
    "        # 如果为测试集，则不加载label\n",
    "        for text in tqdm(csv_data['content']):\n",
    "            examples.append(Example.fromlist([None, text, None], fields))\n",
    "    else:\n",
    "        for text, label in tqdm(zip(csv_data['content'], csv_data['label'])):\n",
    "            examples.append(Example.fromlist([None, text, label], fields))\n",
    "    return examples, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3305it [00:02, 1584.64it/s]\n",
      "200it [00:00, 1766.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# 得到构建Dataset所需的examples和fields\n",
    "train_examples, train_fields = get_dataset(train_df, CONTENT, LABEL)\n",
    "test_examples, test_fields = get_dataset(test_df, CONTENT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建Dataset数据集\n",
    "train_dataset = Dataset(train_examples, train_fields)\n",
    "# train_dataset, valid_dataset = train_dataset.split(0.7)\n",
    "test_dataset = Dataset(test_examples, test_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据`batch_size` 生成 `Dataset` 的 `Iteratior`。常用的有 `Iterator` 和 `BucketIterator` 。其中 `BucketIterator` 是 `Iterator` 的子类，与 `Iterator` 相比，`BucketIterator` 会把相同或相近长度的数据（按 `sort_key`）属性进行排序，这样可以最小化 `pad`。\n",
    "\n",
    "重要参数：\n",
    "1. `dataset`：需要生成`Iterator`的数据集；\n",
    "2. `batch_size`：每个 `batch`的大小；\n",
    "3. `sort_key`：用来为每个 `Example` 进行排序的字段，默认是`None`；\n",
    "4. `shuffle`：每次 `epoch` 是否进行 `shuffle`；\n",
    "\n",
    "重要函数：\n",
    "1. `splits()`：为数据集生成`Iterator`；\n",
    "2. `datasets`：`Tuple` 类型的 `Dataset`，`Tuple`的第一个元素应该是`train`数据集的`Dataset`；\n",
    "3. `batch_sizes`：`Tuple`类型，和`datasets`中的`Dataset`一一对应，表示各个数据集生成`batch`的大小；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "# 同时对训练集和验证集进行迭代器的构建\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    "        (train_dataset, test_dataset), # 构建数据集所需的数据集\n",
    "        batch_sizes=(8, 8),\n",
    "        device=-1, # 如果使用gpu，此处将-1更换为GPU的编号\n",
    "        sort_key=lambda x: len(x.content), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "        sort_within_batch=False,\n",
    "        repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看构建的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = list(val_iter)[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2011', '好书', '南方', '传媒', '营销', '广告', '背后', '故事']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.examples[5].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 50])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.content.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BILSTM+ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRNNConfig(object):\n",
    "    \"\"\"RNN配置参数\"\"\"\n",
    "\n",
    "    # 模型参数\n",
    "    char_embedding_size = 100      # 词向量维度\n",
    "    num_classes = 4        # 类别数\n",
    "    vocab_size = 10000       # 词汇表达小\n",
    "\n",
    "    rnn_layers= 1           # 隐藏层层数\n",
    "    hidden_dims = 64        # 隐藏层神经元\n",
    "    rnn = 'lstm'             # lstm 或 gru\n",
    "\n",
    "    keep_dropout = 0.8 # dropout保留比例\n",
    "    learning_rate = 1e-3    # 学习率\n",
    "\n",
    "    batch_size = 8         # 每批训练大小\n",
    "    num_epochs = 5          # 总迭代轮次\n",
    "\n",
    "    l2_reg_lambda = 1       # l2正则\n",
    "    \n",
    "    print_per_batch = 10    # 每多少轮输出一次结果\n",
    "    save_per_batch = 10      # 每多少轮存入tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络结构定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextBILSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 config:TRNNConfig,\n",
    "                 char_size=200):\n",
    "        super(TextBILSTM, self).__init__()\n",
    "        self.num_classes = config.num_classes\n",
    "        self.learning_rate = config.learning_rate\n",
    "        self.keep_dropout = config.keep_dropout\n",
    "        self.char_embedding_size = config.char_embedding_size\n",
    "        self.l2_reg_lambda = config.l2_reg_lambda\n",
    "        self.hidden_dims = config.hidden_dims\n",
    "        self.char_size = char_size\n",
    "        self.rnn_layers = config.rnn_layers\n",
    "        self.build_model()\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # 初始化字向量\n",
    "        self.char_embeddings = nn.Embedding(self.char_size, self.char_embedding_size)\n",
    "        # 字向量参与更新\n",
    "        self.char_embeddings.weight.requires_grad = True\n",
    "        # attention layer\n",
    "        self.attention_layer = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
    "\n",
    "        # 双层lstm\n",
    "        self.lstm_net = nn.LSTM(self.char_embedding_size, self.hidden_dims,\n",
    "                                num_layers=self.rnn_layers, dropout=self.keep_dropout,\n",
    "                                bidirectional=True)\n",
    "        # FC层\n",
    "        # self.fc_out = nn.Linear(self.hidden_dims, self.num_classes)\n",
    "        self.fc_out = nn.Sequential(\n",
    "#             nn.Dropout(self.keep_dropout),\n",
    "#             nn.Linear(self.hidden_dims, self.hidden_dims),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(self.keep_dropout),\n",
    "            nn.Linear(self.hidden_dims, self.num_classes),\n",
    "        )\n",
    "\n",
    "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
    "        '''\n",
    "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
    "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden] [8, \n",
    "        :return: [batch_size, n_hidden]\n",
    "        '''\n",
    "        # chunk的方法做的是对张量进行分块，返回一个张量列表。但如果指定轴的元素个数被chunks除不尽，最后一块的元素个数会少。\n",
    "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
    "        \n",
    "        # h [batch_size, time_step, hidden_dims] [8, 200, 32]\n",
    "        # 将双向LSTM的激活值相加\n",
    "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
    "        \n",
    "        # 将最后一层隐藏层两个方向权重加起来\n",
    "        # [batch_size, num_layers * num_directions, n_hidden]\n",
    "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
    "        \n",
    "        # [batch_size, 1, n_hidden] [8, 1, 32] 在下标1的位置增加1维\n",
    "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
    "        \n",
    "        '''\n",
    "        self.attention_layer 层会根据lstm层的输出产生一个用于计算attention的weights，\n",
    "        而我希望self.attention_layer产生用于计算attention的weights的过程也进行参数学习，\n",
    "        所以定义了个anttention_layer。\n",
    "        以下几行为自定义attention层，将最后一层隐藏层作为attention权重，输出softmax_w\n",
    "        '''\n",
    "        # atten_w [batch_size, 1, hidden_dims] [8, 1, 32] attention层\n",
    "        atten_w = self.attention_layer(lstm_hidden)\n",
    "        # m [batch_size, time_step, hidden_dims] [8, 200, 32] Tanh激活\n",
    "        m = nn.Tanh()(h)\n",
    "        # atten_context [batch_size, 1, time_step] [8, 1, 200] 每个词对应一个weight\n",
    "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
    "        # softmax_w [batch_size, 1, time_step] [8, 1, 200] softmax归一化\n",
    "        softmax_w = F.softmax(atten_context, dim=-1)\n",
    "        \n",
    "        # context [batch_size, 1, hidden_dims] [8, 1, 32] 所有词加权到lstm的output上\n",
    "        context = torch.bmm(softmax_w, h)\n",
    "        # 减一维\n",
    "        result = context.squeeze(1)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def attention_net(self, lstm_out, lstm_hidden):\n",
    "        \n",
    "        # chunk的方法做的是对张量进行分块，返回一个张量列表。但如果指定轴的元素个数被chunks除不尽，最后一块的元素个数会少。\n",
    "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
    "        \n",
    "        # h [batch_size, time_step, hidden_dims] \n",
    "        # 将双向LSTM的激活值相加\n",
    "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
    "        \n",
    "        # 将最后一层隐藏层两个方向权重加起来\n",
    "        # [batch_size, num_layers * num_directions, n_hidden]\n",
    "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
    "        \n",
    "        # [batch_size, 1, n_hidden]  在下标1的位置增加1维\n",
    "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
    "        \n",
    "        # atten_score [batch_size, 1, time_step]  attention score层\n",
    "        atten_score = torch.bmm(lstm_hidden, h.transpose(1, 2))\n",
    "        \n",
    "        # atten_weight [batch_size, 1, time_step] softmax归一化（attention distribution层）\n",
    "        atten_weight = F.softmax(atten_score, dim=-1)\n",
    "        \n",
    "        # [batch_size, 1, n_hidden] 加权输出值\n",
    "        context = torch.bmm(atten_weight, h)\n",
    "        result = context.squeeze(1)\n",
    "        return result\n",
    "    \n",
    "\n",
    "    def forward(self, char_id):\n",
    "        '''\n",
    "        :param char_id: torch.from_numpy(np.array(input[0])).long()\n",
    "        词id的矩阵，本例中大小为 [batch_size=8, len_seq=200]\n",
    "        '''\n",
    "        \n",
    "        # sen_char_input: [batch_size, len_seq, embedding_dim], torch.Size([8, 200, 100])\n",
    "        # char_embeddings 后每个词都嵌入到一个100维的矩阵中，输出变为3维张量\n",
    "        sen_char_input = self.char_embeddings(char_id)\n",
    "        \n",
    "        # input : [len_seq, batch_size, embedding_dim] \n",
    "        # 将张量1维2维位置调换，permute传入每个维度期望的index\n",
    "        sen_input = sen_char_input.permute(1, 0, 2)\n",
    "        \n",
    "        # output : [batch_size, len_seq, n_hidden * 2] 双向lstm的输出\n",
    "        output, (step_hidden_state, step_cell_state) = self.lstm_net(sen_input)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        \n",
    "        # step_hidden_state : [batch_size, num_layers * num_directions, n_hidden] 每个时间步的隐藏状态值\n",
    "        step_hidden_state = step_hidden_state.permute(1, 0, 2)\n",
    "        \n",
    "        # 带权重的attention层输出 [batch_size, n_hidden]\n",
    "        atten_out = self.attention_net(output, step_hidden_state)\n",
    "        return F.softmax(self.fc_out(atten_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_func(sub_train_):\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    for epoch, batch in enumerate(sub_train_):\n",
    "        optimizer.zero_grad()\n",
    "        # text = batch.text.permute(1, 0)\n",
    "        predicted = model(batch.content)\n",
    "\n",
    "        loss = loss_funtion(predicted, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch.batch_size\n",
    "        running_corrects += torch.sum(predicted.argmax(1) == batch.label).item()\n",
    "        writer.add_scalar('Train/Loss', running_loss,epoch)\n",
    "        writer.add_scalar('Train/Acc',running_corrects,epoch)\n",
    "\n",
    "    train_size = sub_train_.batch_size * sub_train_.iterations\n",
    "    epoch_loss = running_loss / train_size\n",
    "    epoch_acc = running_corrects / train_size\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def test_func(sub_test_):\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    for epoch, batch in enumerate(sub_test_):\n",
    "        with torch.no_grad():\n",
    "            # text = batch.text.permute(1, 0)\n",
    "            predicted = model(batch.content)\n",
    "            loss = loss_funtion(predicted, batch.label)\n",
    "\n",
    "            running_loss += loss.item() * batch.batch_size\n",
    "            running_corrects += torch.sum(predicted.argmax(1) == batch.label).item()\n",
    "            writer.add_scalar('Test/Loss', running_loss, epoch)\n",
    "            writer.add_scalar('Test/Acc',running_corrects,epoch)\n",
    "\n",
    "    train_size = sub_test_.batch_size * sub_test_.iterations\n",
    "    epoch_loss = running_loss / train_size\n",
    "    epoch_acc = running_corrects / train_size\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 走起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finup/miniconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/Users/finup/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:134: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 47 seconds\n",
      "\tLoss: 1.2363(train)\t|\tAcc: 49.8%(train)\n",
      "\tLoss: 1.0654(valid)\t|\tAcc: 70.5%(valid)\n",
      "Epoch: 2  | time in 0 minutes, 49 seconds\n",
      "\tLoss: 0.9987(train)\t|\tAcc: 74.4%(train)\n",
      "\tLoss: 0.9925(valid)\t|\tAcc: 74.0%(valid)\n",
      "Epoch: 3  | time in 0 minutes, 48 seconds\n",
      "\tLoss: 0.8978(train)\t|\tAcc: 84.4%(train)\n",
      "\tLoss: 0.9435(valid)\t|\tAcc: 80.0%(valid)\n",
      "Epoch: 4  | time in 0 minutes, 48 seconds\n",
      "\tLoss: 0.8553(train)\t|\tAcc: 88.3%(train)\n",
      "\tLoss: 0.9059(valid)\t|\tAcc: 84.5%(valid)\n",
      "Epoch: 5  | time in 0 minutes, 47 seconds\n",
      "\tLoss: 0.8406(train)\t|\tAcc: 89.9%(train)\n",
      "\tLoss: 0.9185(valid)\t|\tAcc: 83.0%(valid)\n"
     ]
    }
   ],
   "source": [
    "model = TextBILSTM(TRNNConfig, char_size=len(CONTENT.vocab))\n",
    "model.train()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=TRNNConfig().learning_rate)\n",
    "loss_funtion = F.cross_entropy\n",
    "\n",
    "for epoch in range(TRNNConfig().num_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(train_iter)\n",
    "    valid_loss, valid_acc = test_func(val_iter)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finup/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:113: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "running_corrects = 0\n",
    "for epoch, batch in enumerate(val_iter):\n",
    "    with torch.no_grad():\n",
    "        # text = batch.text.permute(1, 0)\n",
    "        predicted = model(batch.content)\n",
    "        loss = loss_funtion(predicted, batch.label)\n",
    "\n",
    "        running_loss += loss.item() * batch.batch_size\n",
    "        running_corrects += torch.sum(predicted.argmax(1) == batch.label).item()\n",
    "        writer.add_scalar('Test/Loss', running_loss, epoch)\n",
    "        writer.add_scalar('Test/Acc',running_corrects,epoch)\n",
    "\n",
    "train_size = train_iter.batch_size * train_iter.iterations\n",
    "epoch_loss = running_loss / train_size\n",
    "epoch_acc = running_corrects / train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
